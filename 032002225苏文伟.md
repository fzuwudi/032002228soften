# （1.1）Github链接 ： https://github.com/1314-1/2022.K-
# 一、PSP表格
## （2.1）&& （2.2）
##  ![image](https://user-images.githubusercontent.com/78329188/191045726-cc4ddea2-d0ec-4127-804b-3c6e5145fe3d.png)
# 二、任务要求的实现
## （3.1）项目设计与技术栈。
### 从阅读完题目到完成作业，这一次的任务被我拆分成了五个环节：
#### 1、首先我把爬虫和数据录入Excel当成一个环节，在爬数据的时候顺便录入了。用到了xlwt这个库。
#### 2、在完成作业的过程中，我发现国家卫健委的反爬虫技术很有一套（这也是我耗时最长的一个环节，原本写好的要推掉一部分，心累...），最后我用的是pyppeteer来躲避反爬虫机制，不过缺点是比较慢，而且网不好的时候很容易超时。（算了，能爬出来也就行了...）
#### 3、对港澳台数据的特殊处理，因为我录入Excel表的数字是文本格式的，所以我借助Excel自带的函数来对港澳台的数据进行处理。
#### 4、每日热点，比较今天和前一天。 （ “朴实无华” ）。
#### 5、数据可视化利用的FineBI这个工具。
## （3.2）爬虫与数据处理。
### 说明业务逻辑，简述代码的设计过程，并对关键的函数或算法进行说明。
#### 1、业务逻辑：
##### 代码适用Python语言编写的。主函数创建一个Excel表，然后调用一系列的函数，通过正则表达式获取字符串然后录入Excel表格中，主函数结束之后保存这个Excel表格。之后在Excel对港澳台和其他数据进行处理。再把处理好的Excel直接导入FineBI生成可视化界面。
#### 2、代码设计过程：
##### 主函数main主要就是创建Excel还有对固定的单元格进行数值设置和对卫健委官网的那几个页面进行循环查询。main函数会调用一个spider函数，这个函数主要是解析网页加上使用正则表达式对Excel写入数据。spider又会调用一个pyppteer_fetchUrl的函数，主要是通过打开页面来反爬虫的。
## （3.3）数据统计接口部分的性能改进：
##### 消耗最大的函数（毕竟基本都是它在实现）
##### ![](https://img2022.cnblogs.com/blog/2965727/202209/2965727-20220919220659011-1215093092.png)
##### ![try py](https://user-images.githubusercontent.com/78329188/191054620-cc4b355a-e719-49f6-a39f-a5274288e36d.png)
##### 消耗最大的是它内置的函数，现在不会改。
## （3.4）每日热点的实现思路：
##### 没时间了，就直接今天与前天的疫情人数进行比较了。
## （3.5）数据可视化界面的展示：
##### ![](https://img2022.cnblogs.com/blog/2965727/202209/2965727-20220919222242082-1868234985.png)
##### 组件就是FineBI
# 三、心得体会
##### （4.1）对我来说算是一次成长吧，虽然基础任务也完成的不好,卫健委的数据格式有点多变，时间和网络问题最后爬了十多页，但是应该是可以爬30多页的（疫情刚刚开始的时候，各几天换个格式，我抵不住了），但是也算是学到了一些东西。狠狠地被push了，几个大作业一起来，润了......
