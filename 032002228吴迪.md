GitHub链接：https://github.com/fzuwudi/Software-Homework.git
# 一、PSP表格
| PSP2.1 |Personal Software ProcessStages  |预估耗时|实际耗时|
|--|--|--|--|
|Planning  |计划  |30|30|
|· Estimate | · 估计这个任务需要多少时间|30|30
|Development|开发|1485|1795
|· Analysis|· 需求分析 (包括学习新技术)|960|1200
|·Design Spec| · 生成设计文档|30|30|
|· Design Review|· 设计复审|20|20
|· Coding Standard|· 代码规范 (为目前的开发制定合适的规范)|20|20|
|· Design |· 具体设计|20|30
|· Coding|· 具体编码|240|270
|· Code Review |· 代码复审|15|15
|· Test|· 测试（自我测试，修改代码，提交修改）|180|210
|Reporting |报告|125|155
|· Test Report|· 测试报告|90|120
|· Size Measurement |· 计算工作量|15|15
|· Postmortem & Process Improvement Plan|· 事后总结, 并提出过程改进计划|20|20
||· 合计|1640|1980
# 二、任务要求的实现

## 2.1项目设计与技术栈

#### 2.1.1本次任务被拆分成的环节数量
本次任务主要被拆分为五个环节，分别是：阅读题目分析题意、学习相关必备技能、使用技能完成解答、尽力完善不理想结果、不断的反思与改进。

#### 2.1.2完成各个环节所通过的渠道以及所使用的方法
（1）通过反复阅读题目弄清题目要求，明确需要学习的技能有哪些。
（2）主要通过上网查询、听网课、询问同学三种形式学习相关技能。
（3）首次写完程序后尝试运行，发现程序bug并努力修复，提升程序的质量。
（4）针对无法提取到数据的情况，我会取找出对应的文本，结合错误情况分析，找出问题所在。
（5）每天学习结束后，我会思考今天学了什么，哪些问题多次尝试后依旧无法解决，哪些方法比较好用。

#### 2.1.3本次任务所使用的技术栈
（1）编程：python
（2）数据分析：matlab
（3）数据可视化：excel、镝数图表
## 2.2爬虫与数据处理

#### 2.2.1简述代码的设计过程（几个函数，之间的关系）
由题目要求可知，需要爬取国家卫健委每日疫情数据，时间跨度为疫情开始至今。具体设计过程如下：
（1）发现国家卫健委具有反爬机制，故使用cookie。
（2）首先设计了一个用于爬目录的代码，用于爬取每日发布的疫情文章所对应的网址。
（3）接着设计一段代码，用于读取每日疫情文章对于的文本。
（4）最后设计一段代码，用于统计全国新增确证、全国新增无症状、各省新增确诊、各省新增无症状，并导到excel中。

#### 2.2.2对关键的函数或算法的说明
（1）爬目录的方法：正则表达式，检索到网址和日期，而后存储与一个.txt文档中。
（2）由于使用的cookie具有时效性，所以先将每日的文章所对应的文本导成.txt（需要操作多次，并且更换cookie），然后再对导出的文本爬取具体数据。
（2）爬取具体数据的方法：正则表达式，检索到具体数据。正则表达式主要使使用非贪婪模式的匹配。

## 2.3数据统计接口部分的性能改进

#### 2.3.1在数据统计接口的性能上所花费的时间
已经下载了visual studio，但确实没有更多的时间能够用来学习和完成数据统计接口这部分的内容了。在这部分，主要是一些自己的分析，大概花了20分钟。

#### 2.3.2说明改进的思路
由于程序较为冗长，应该将功能相同的代码段封装成函数。

#### 2.3.3展示程序中消耗最大的函数
由于一直都是在检索匹配，所以使用消耗最大的函数是findall()。

## 2.4每日热点的实现思路

#### 2.4.1简要介绍实现该功能的算法原理
每日热点的主要思想为：
（1）将每个省份的新增确诊和新增无症状数量合并为一项，记为该省的总新增人数，将某省在i日的总新增记为x(i)，则该省在（i-1）日的总新增为x(i-1)。
（2）若满足x(i)>x(i-1)且x(i)≥50，即在i日的总新增大于在第i-1日的总新增且第i日的总新增大于等于50，说明该省在第i日可以被列入每日热点中。

#### 2.4.2步骤流程图和核心代码实现
（1）步骤流程图：
[![2jZjo.png](https://img-blog.csdnimg.cn/img_convert/eb10498f335de908dbfb6e506b40894e.png)](https://imgloc.com/i/2jZjo)
（2）以下为使用matlab进行数据处理的代码截图：
[![2FKay.png](https://img-blog.csdnimg.cn/img_convert/fd6350eb408565c963f9d73788e06405.png)](https://imgloc.com/i/2FKay)
（3）考虑到时效性，只对近14日的日期做每日热点分析，使用matlab分析后，对数据进行整合，整理结果如下：
[![2uEaN.png](https://img-blog.csdnimg.cn/img_convert/30df3375dc883defd1230448e7f1b628.png)](https://imgloc.com/i/2uEaN)

#### 2.4.3简要谈谈所采用算法的优缺点与可能的改进方案
（1）算法的优点：能够通过简单、易于理解简单的方法将全国新增总数较多和增势较为迅猛的省份快速筛选出来。
（2）算法缺点：没有使用机器学习算法。只使用了初步的统计方法，精确性有待提高，没有通过较为复杂的分析推导，只能够大概的反映出疫情形式。
（3）可能的改进方案：对每个省份计算增幅，分析14日以来每日的增幅，观察其规律，对该省份接下来的增幅进行预测，判断该省份的风险性。

## 2.5数据可视化界面

#### 2.5.1介绍数据可视化界面的组件和设计的思路
（1）数据可视化主要通过使用excel做全国各省份的热力地图。
（2）设计思路：将每个省份14天以来的新增确诊病例相加。对14天的新增确诊病例数量进行等级划分。记14天的新增确诊病例数量为X，划分等级为Y，划分方式为：
| 14天的新增确诊病例数量X | 划分等级Y |
|--|--|
| [0,50) | 1 |
| [50,150) | 2 |
|  [150,250) | 3 |
 |  [250,350) | 4 |
   | [350,450) | 5|
  |   [450,∞) | 6 |

#### 2.5.2数据可视化界面的展示
[![2qdhC.jpg](https://img-blog.csdnimg.cn/img_convert/07df321fb51f1d8c078c4f4176d15f98.jpeg)](https://imgloc.com/i/2qdhC)](https://imgloc.com/i/2qRC5)

# 三、心得体会
（1）首先，关于本次作业，我认为我提交的作品是一个不完整的作品，完成的并不好。很多方面都做得不到位，特别是在数据的爬取这一步，因为目前能力确实有限，设计不出适合所有格式的文本的代码，直接导致无法爬取全部的九百多条的数据。数据爬取这块确实花了很多时间，最开始是想用稍微灵活一点的方法去设计一套程序爬取数据，但效果很不理想。多次尝试后，最后用最为朴素的方法（一个一个匹配）都没办法全部爬取成功。
（2）在本次作业中，我连python都是现学的，更别提爬虫等一些技术了，所以完成作业的过程是挺困难的，也挺折磨的。这也让我深刻的意识到在过去的两年中，我一直不愿尝试新事物，不愿学习课外有用的知识，浪费了太多的时间。
（3）虽然完成的并不好，但我在完成作业的过程中我学习到了很多新的知识。现在对这些知识的掌握还是浮于表面，但对比之前什么都不知道的情况已经好挺多的了。
（3）还有就是在完成作业过程中在心理状态方面的改变，之前会一直纠结于我什么都不会，我好菜，但现在发生变化了，我觉得不会就学，没什么大不了的。也许在短期之内并不能学的好、学的精，但我相信如果认真学习一段时间就一定能够学好的。 
